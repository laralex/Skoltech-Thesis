\chapter{Conclusions}\label{chapter:conclusions}

In this Master thesis, we firstly implemented an Augmented Reality application for Android mobile devices. It allows to detect surfaces in the camera view and place full-body human avatars, as if they stand on a surface for real. The correct images of the avatars are synthesized by a DNN, which was specifically integrated to work natively on the mobile device hardware, in real-time. The integration includes inference of a human body 3D model for a certain body pose, and projection of it as an image of the neural network's inputs. By means of quantization, data layout and parallel GPU processing, we arranged an efficient way of generating the input data. As a result, the input data can be directly forwarded to the DNN processing, without additional memory reordering required. Using Qualcomm Snapdragon hardware capabilities with Digital Signal Processor computing unit, we achieved real-time DNN inference with latency well below the minimum requirement and sufficient resolution of the synthesized images. Even bigger resolutions are available, still within real-time performance. We propose to use an algorithmic approach of dynamic cropping of the physical camera's view frustum, to always render input images with avatar being at the center and with only the body parts that will be visible in the current view of AR. This led to automatically better image quality when looking at the avatar from far away.

Secondly, we carried out research on improving the training procedure of the baseline DNN, to achieve higher quality of images that can be encountered in the AR scenario. Using the nature of the DNN's input data, we propose to use camera-space augmentations to train the neural network on zoomed images. We studied how such training can improve stability of synthesized images to minor shifts of body pose or viewpoint. On the other hand, it may also reduce original visual quality of full-body images generated by the baseline, or amplify visual artifacts related to overfitting, discrepancy of statistical properties on different scales of zooms, and out-of-distribution rendering of body parts that were never seen during training. We tried to overcome those issues using well known regularization techniques, as well as our own insights. In attempt to preserve the original DNN architecture, the effect of the researched adjustments proved to be ever so slight. Many of them improve convergence speed, yet speeding up emergence of the overfitting artifacts. Although we had a few successful experiments that partly solve the issues, they come at a cost of being less efficiently implemented on the mobile hardware, leading to drastic decrease in the real-time performance. 

We conclude this work, declaring that all the project tasks were completed and the goal of the Master thesis was achieved. In the future, we strive to solve the remaining visual artifacts by overlooking and significantly deviating from the baseline architecture, using the knowledge obtained during this work. The mobile AR experience is also subject to expansion towards rendering of multiple avatars by a single neural network. Also, since the Qualcomm Snapdragon hardware platform we used can also be found in other mobile devices, such as AR glasses, we expect to integrate the full-body avatars here as well. All the efforts that we made prove that the embedded real-time artificial intelligence is achievable for the state-of-the-art hardware. However, it requires careful and efficient integration into the products. The approaches used in this work may be relevant to projects on AI-based immersive telecommunication, Augmented/Virtual Reality, user-device interaction, real-time processing of audio/video, etc. 

We want to once again emphasize the negative impact of inefficiencies during storing or reading of data in computer memory. If the data layout is too sparse or accessed in non-sequential patterns, it may easily reduce the performance by half, as we have shown in this work. It can bewilder software developers and wrongfully convince that a task is unfeasible for real-time execution.  Regarding the quality of DNN results, sometimes it's more rewarding to think of an algorithmic solution to the problems, rather than trying to make the DNN generalize all the corner cases. For example, we applied that to improve far-away image quality in AR, by simply never passing the far-away inputs to the DNN to begin with.

