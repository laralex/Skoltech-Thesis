\chapter{Conclusions}\label{chapter:conclusions}

In this Master's thesis, we firstly implemented an Augmented Reality application for Android mobile devices. It allows to place full-body human avatars in the camera view, as if they actually stood in the real world. The avatar images are synthesized by a DNN, which was specifically integrated to work in real-time on the mobile device hardware. The integration includes inference of a human body 3D model for a certain body pose, and projection of it as an image, which becomes an input for the neural network. Using the quantization of the DNN, the parallel GPU processing, and by rearranging the data flow, we found an efficient way of generating the input data on the mobile device. As a result, the input data can be directly forwarded to the DNN inference, without additional memory reordering required. Using the capabilities of Qualcomm Snapdragon hardware with its Digital Signal Processor computing unit, we achieved the real-time DNN inference with latency well below the minimum requirement and sufficient resolution of the synthesized images. Even bigger resolutions are available, still within the real-time performance. We propose to use an algorithmic approach of dynamic cropping of the camera's view frustum. With this approach, the input images are rendered so that only the body parts of the avatar which are visible in the current AR view are present, thus minimizing the amount of wasted computations for rendering the unseen parts. This led to the automatically better image quality when looking at the avatar from far away.

Secondly, we carried out research on improving the training procedure of the baseline DNN, to achieve a higher quality of images that can be encountered in the AR scenario. Using the nature of the DNN's input data, we propose to use camera-space augmentations to train the neural network on zoomed images. We studied how such training can improve the stability of synthesized images to minor shifts of a body pose or a viewpoint. On the other hand, it may also reduce the original visual quality of the full-body images generated with the baseline model. It can also amplify the visual artifacts related to the overfitting, the discrepancy of statistical properties on different scales of zooms, and the out-of-distribution rendering of the body parts that were never seen during training. We tried to overcome those issues using the well-known regularization techniques, as well as our own insights. In an attempt to preserve the original DNN architecture, the effect of the researched adjustments proved to be ever so slight. Many of them improve the convergence speed, yet speed up the emergence of the overfitting artifacts. Although we had a few successful experiments that partly solve the issues, they come at a cost of being less efficiently implemented on the mobile hardware, leading to a drastic decrease in the real-time performance. 

We conclude this work, declaring that all the project tasks were completed and the goal of the Master's thesis was achieved. In the future, we strive to solve the remaining visual artifacts by overlooking and significantly deviating from the baseline architecture, using the knowledge obtained during this work. The mobile AR experience is also subject to expansion towards the rendering of multiple avatars by a single neural network. Also, since the Qualcomm Snapdragon hardware platform we used can also be found in other mobile devices, such as AR glasses, we expect to integrate the full-body avatars here as well. All the efforts that we made prove that the embedded real-time artificial intelligence is achievable for the state-of-the-art mobile hardware. However, it requires a careful and efficient integration into the products. The approaches that we used in this work may be relevant to the projects on AI-based immersive telecommunication, Augmented/Virtual Reality, real-time processing of audio/video, etc. 

We want to once again emphasize the negative impact of inefficiencies when storing or reading the data in the computer memory. If the data layout is too sparse, or accessed with non-sequential patterns, it may easily reduce the performance by half, as we have shown in this work. It can bewilder the software developers and wrongfully convince that a task may be unfeasible for real-time execution.  Regarding the quality of the DNN results, sometimes it is more rewarding to think of an algorithmic solution to the problems, rather than trying to make the DNN generalize to all the corner cases. For example, we applied that to improve the far-away image quality in AR, by simply never passing the far-away inputs in the DNN, to begin with.

