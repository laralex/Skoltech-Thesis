\chapter{Relevant mobile application code}
\label{appendix-code}
%\setkeys{Gin}{draft}

In this appendix we present listings of code that are the most relevant to realtime input generation of neural rendering DNN on a mobile device. We omit about 85\% of the code related to setup of the Android user interface, main loop, logging, loading of assets and configuration, interaction with the user, initialization of OpenGL components, selection of features, animations, rendering of the camera frame, tracked planes, etc. We also do not find it necessary to publish the full Python code for DNN training, since the adjustments presented in the Section \ref{methods:zooms} are reproducible from the description.

\myfilelisting[language=Java]{\codefp/Generator.java}[appendix-code:generator]
<The Generator class uses SNPE neural network API to map certain pre-allocated data buffers as locations of DNN input and output. Thus, on each inference no additional memory allocation is invoked. You can notice, that the network is created with multiple "tries", in order to try different combinations of security parameters for SNPE initialization. Without it, the network might fail to load required third party libraries.>
\myfilelisting[language=Java]{\codefp/BenchmarkRunner.java}[appendix-code:benchmarkrunner]
<The BenchmarkRunner class shows how in-application benchmarking is implemented. We measure running average of frametime, as well temperature using a mobile sensor. >

%\myfilelisting[language=Java]{\codefp/FloatAnimation.java}
%\myfilelisting[language=Java]{\codefp/InferedImage.java}
%\myfilelisting[language=Java]{\codefp/NeuralFramebuffer.java}

\myfilelisting[language=Java]{\codefp/Frustum.java}[appendix-code:frustum]
<The Frustum class illustrates how near/far/bottom/top/left/right parameters of a view frustum correspond to a projection $4\times4$ matrix.>
\myfilelisting[language=Java]{\codefp/ProjectionCropper.java}[appendix-code:projectioncropper]
<The ProjectionCropper class transforms a screen projection matrix into a crop, given crop center and height in space of camera coordinates.>
\myfilelisting[language=Java]{\codefp/NeuralProjectionCorrectionSelector.java}
<The NeuralProjectionCorrectionSelector class does projection matrix scaling, to make it render square images (as the neural network was trained), also it modifies the projection to vertically flip all images, to account to the difference of physical layout of pixels in OpenGL and SNPE.>
%\myfilelisting[language=Java]{\codefp/NeuralRenderer.java}
\myfilelisting[language=Java]{\codefp/SmplxInferer.java}[appendix-code:smplx]
<The SmplxInferer implements the full algorithm of SMPL-X inference, except for blending of pose blendshapes, since they would be too costly to calculate on every frame.>

\myfilelisting[language=GLSL]{\codefp/neural_render_smplx.vert}[appendix-code:vertexshader]
<This is the main Vertex shader used for posing of every vertex in a body mesh from a default pose into a certain pose, given 55 matrices of joints rotations. For each vertex, the shader receives indices of the most significant joints, and finds a weighted sum of matrices accordingly. Then, each vertex is projected from the local body coordinate space, into the world space, into the camera space, and into the image coordinate space. This all is done with a single $4\times4$ matrix that merges the 3 transforms.>

\myfilelisting[language=GLSL]{\codefp/neural_render.frag}[appendix-code:fragmentshader]
<This is the main Fragment shader used for rasterization of the input frame for the neural network. For each pixel, is uses interpolated texture coordinates that allow to sample a certain point at the neural texture. We use multiple FP16 4-channel slices to construct the $N$-channel neural texture. The shader samples the slices in a loop, then quantizes the floating-point numbers into INT8 and using bit-shift packs the values into the output frame, which can store up to 16 bytes of data per pixel (4 channels, 32-bit integer number each).>

%\setkeys{Gin}{draft=false}

\clearpage
\newpage
