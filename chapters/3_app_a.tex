\chapter{Relevant mobile application code}

In this appendix we present the snippets of code that are most relevant to input generation for the DNN on mobile in real-time. We omit about 85\% of the code related to setup of the Android user interface, main loop, logging, loading of assets and configuration, interaction with the user, initialization of OpenGL components, rendering of the camera frame, tracked planes, etc. We also don't publish the Python code for DNN training, since the adjustments presented in the Section \ref{methods:zooms} are descriptive enough for replication.


\myfilelisting[language=Java]{\codefp/Generator.java}
<The Generator class uses SNPE neural network API to map certain pre-allocated data buffers as locations of input and output. Thus, no additional memory allocation takes place on every inference. You can notice, that the network is created with multiple "tries", in order to try different security parameters of SNPE initialization. Without it, the network might fail to load required third party libraries.>
\myfilelisting[language=Java]{\codefp/BenchmarkRunner.java}
<The BenchmarkRunner class shows how in-application benchmarking is implemented. We measure running average of frametime, as well temperature using a mobile sensor. >

%\myfilelisting[language=Java]{\codefp/FloatAnimation.java}
%\myfilelisting[language=Java]{\codefp/InferedImage.java}
%\myfilelisting[language=Java]{\codefp/NeuralFramebuffer.java}

\myfilelisting[language=Java]{\codefp/Frustum.java}
<The Frustum class illustrates how near/far/bottom/top/left/right parameters of view frustum correspond to a projection $4\times4$ matrix.>
\myfilelisting[language=Java]{\codefp/ProjectionCropper.java}
<The ProjectionCropper class transforms a screen projection matrix into a crop, given crop center and height in camera coordinates.>
\myfilelisting[language=Java]{\codefp/NeuralProjectionCorrectionSelector.java}
<The NeuralProjectionCorrectionSelector class does projection matrix scaling, to make it render square images (as the neural network was trained), also it modifies the projection to vertically flip all images, to account to the difference of physical layout of pixels in OpenGL and SNPE.>
%\myfilelisting[language=Java]{\codefp/NeuralRenderer.java}
\myfilelisting[language=Java]{\codefp/SmplxInferer.java}
<The SmplxInferer implements the full algorithm of SMPL-X inference, except for blending of pose blendshapes, since they would be too costly to calculate on every frame (and also the visual difference is suppressed by further neural processing).>

\myfilelisting[language=GLSL]{\codefp/neural_render_smplx.vert}
<This is the main Vertex shader used for posing of every vertex in a body mesh from a default pose into a certain pose, given 55 matrices of joints rotations. For each vertex, the shader receives indices of the most significant joints, and finds a weighted sum of matrices accordingly. Then, each vertex is projected from the local body coordinate space, into the world space, into the camera space, and into the image coordinate space. This all is done with a single $4\times4$ matrix that merges the 3 transforms.>

\myfilelisting[language=GLSL]{\codefp/neural_render_uv_varpack_components_size.frag}
<This is the main Fragment shader used for rasterization of the input frame for the neural network. For each pixel, is uses interpolated texture coordinates that allow to sample a certain point at the neural texture. We use multiple FP16 4-channel slices to construct the $N$-channel neural texture. The shader samples the slices in a loop, then quantizes the floating-point numbers into INT8 and using bit-shift packs the values into the output frame, which can store up to 16 bytes of data per pixel (4 channels, 32-bit integer number each).>

\clearpage
\newpage
